#!/usr/bin/env python3
"""
Creates charge histograms from hdf5 files made from `wavedump` or
`acquire-waveforms`.
"""

from __future__ import print_function, division
import h5py
import numpy as np
from scipy import signal
import os
import sys
from enum import Enum

canvas = []

class Institution(Enum):
    """
    Note: This must be kept in sync with the values in btl_qa.sql.
    """
    caltech = 'Caltech'
    uva = 'UVA'
    rome = 'Rome'

    def __str__(self):
        return self.value

def iqr(x):
    return np.percentile(x,75) - np.percentile(x,25)

def get_threshold_crossing(x, data, threshold=0.4, rising=True):
    """
    Returns the times at which the waveforms in `x` cross `threshold*100`% of
    their minimum value.
    
    WARNING: In cases where a pulse is cut off at the start/end of an event, this function produces a runtime warning.
    """
    data = np.asarray(data)
    argmin = np.argmin(data,axis=-1)
    thresholds = threshold*data[np.arange(data.shape[0]),argmin]
    if rising:
        il = data.shape[1]-np.argmax(((np.arange(data.shape[1]) < argmin[:,np.newaxis]) & (data > thresholds[:,np.newaxis]))[:,::-1],axis=-1)-1
        ir = il + 1
        ir[ir >= data.shape[1]] = data.shape[1]-1
        i = np.arange(data.shape[0])
    else:
        ir = np.argmax(((np.arange(data.shape[1]) > argmin[:,np.newaxis]) & (data > thresholds[:,np.newaxis])),axis=-1)
        il = ir - 1
        il[il < 0] = 0
        i = np.arange(data.shape[0])
    return x[il] + (thresholds-data[i,il])*(x[ir]-x[il])/(data[i,ir]-data[i,il])

def get_rise_time(x, data):
    t10 = get_threshold_crossing(x, data, 0.1)
    t90 = get_threshold_crossing(x, data, 0.9)
    return t90 - t10

def get_fall_time(x, data):
    t10 = get_threshold_crossing(x, data, 0.1, rising=False)
    t90 = get_threshold_crossing(x, data, 0.9, rising=False)
    return t10 - t90

def get_times(x, data, baseline=10):
    """
    Returns the times at which the waveforms in `x` cross 40% of their minimum
    value.
    """
    data = np.asarray(data)
    # Get the first 10 ns of every waveform to calculate the noise level
    noise = iqr(data[:,np.where(x < x[0] + baseline)[0]])
    # Get events with a pulse
    pulses = np.min(data,axis=-1) < -noise*5
    # Select events with pulses. If there are no matches (which might be the
    # case for the triggering channel), then don't apply the selection.
    if np.count_nonzero(pulses):
        data = data[pulses]
    argmin = np.argmin(data,axis=-1)
    threshold = 0.4*data[np.arange(data.shape[0]),argmin]
    return x[data.shape[1]-np.argmax(((np.arange(data.shape[1]) < argmin[:,np.newaxis]) & (data > threshold[:,np.newaxis]))[:,::-1],axis=-1)-1]

def get_window(x, data, left=1, right=10):
    """
    Returns the indices start and stop over which you should integrate the
    waveforms in `x`. The window is found by calculating the median hit time
    for all pulses in `x` and then going back `left` ns and forward `right` ns.
    """
    data = np.asarray(data)
    t = get_times(x,data)
    mean_hit_time = np.median(t)
    a, b = np.searchsorted(x,[mean_hit_time-left,mean_hit_time+right])
    if a < 0:
        a = 0
    if b > len(x) - 1:
        b = len(x) - 1
    return a, b

def get_spe_window(x, start, integration_time):
    """
    Returns the indicies over which the SPE analysis should be integrated.

    `start` and `integration_time` are in nanoseconds, not indexes.
    `start` is relative to the trigger, so `start = 0` is not the first sample,
    but rather the time the trigger fired.
    """
    time_per_index = x[1] - x[0]
    a = int(np.abs(x - start).argmin())
    if a >= len(x) - 1:
        print('SPE integration start time exceeds the acquisition window! Quitting...', file=sys.stderr)
        sys.exit(1)
    b = int(np.round(a + integration_time / time_per_index))
    if b > len(x) - 1:
        print('SPE integration time is too long! Quitting...', file=sys.stderr)
        sys.exit(1)
    return (a,b)

def integrate(x, data, a, b):
    """
    Integrate all waveforms in `data` with times `x`.
    """
    # i = v/r
    # divide by 50 ohms to convert to a charge
    if np.ndim(data) == 2:
        return -np.trapz(data[:,a:b],x=x[a:b])*1000/50.0
    else:
        return -np.trapz(data[a:b],x=x[a:b])*1000/50.0

def get_bins(x, cutoff=None):
    """
    Returns bins for the data `x` using the Freedman Diaconis rule. See
    https://en.wikipedia.org/wiki/Freedman%E2%80%93Diaconis_rule.
    """
    x = np.asarray(x)

    orig_x = x.copy()

    if cutoff is not None:
        x = x[x > cutoff]

    if len(x) == 0:
        return np.arange(0,100,1)
    
    bin_width = 0.5*iqr(x)/(len(x)**(1/3.0))

    if bin_width == 0:
        print('Zero bin width! Quitting...', file=sys.stderr)
        sys.exit(1)

    min = np.percentile(orig_x,1)
    max = np.percentile(x,99)
    return np.arange(min,max,bin_width)

def chunks(lst, n):
    """
    Yield successive n-sized chunks from lst.
    """
    for i in range(0, len(lst), n):
        yield (i,i + n)

def convert_data(f, group, channel, start, stop):
    """
    Reads data from opened hdf5 file `f`. Gets the events from `start` to
    `stop` in the dataset `channel`.
    """    
    if 'data_source' in f[group].attrs:
        if f[group].attrs['data_source'] == b'CAEN':
            
            xinc = 1/(f[group].attrs['drs4_frequency'] * 10**6)
            points = f[group].attrs['record_length']
            x = np.linspace(0, xinc * points, int(points)) - xinc * points * (1 - f[group].attrs['post_trigger']/100)
            
            # While `y` is measured in volts, it's only relatively. We could
            # use the DC offset to determine the absolute voltage, but the
            # DC offset isn't well defined. Setting it to about 22000 (DAC
            # units) means approximately no offset is added, but not
            # exactly. This shouldn't matter much because we use a baseline
            # subtraction method anyways.
            y = f[group][channel][start:stop]/2**12
    elif 'yinc' in dict(f[channel].attrs):
        # FIXME: All of the code below assumes that the datasets are in no
        # group. `acquire-waveforms` should be updated first if we want to
        # be able to use this function for oscilloscope data. 
        x = f[channel].attrs['xorg'] + np.linspace(0,f[channel].attrs['xinc']*f[channel].attrs['points'],int(f[channel].attrs['points']))
        # FIXME: I believe the else block in this if/else statement was for
        # a type of hdf5 format that we no longer use.
        if True: # ':WAVeform:FORMat' in dict(f['settings'].attrs) and f['settings'].attrs[':WAVeform:FORMat'] != 'ASC':
            # convert word values -> voltages if the data was saved in a non-ascii format
            y = f[channel][start:stop]*f[channel].attrs['yinc'] + f[channel].attrs['yorg']
        else:
            y = f[channel][start:stop]
    else:
        # In older versions of the code, I stored xorg, xinc, etc.
        # in the main HDF5 group and not on a per channel basis
        x = f.attrs['xorg'] + np.linspace(0,f.attrs['xinc']*f.attrs['points'],int(f.attrs['points']))

        if ':WAVeform:FORMat' in dict(f['settings'].attrs) and f['settings'].attrs[':WAVeform:FORMat'] != 'ASC':
            # convert word values -> voltages if the data was saved in a non-ascii format
            y = f[channel][start:stop]*f.attrs['yinc'] + f.attrs['yorg']
        else:
            y = f[channel][start:stop]
    return x*1e9, y

def low_filter_SPE(x, y):
    """
    Returns `y` through a low pass filter. Edit the cutoff frequency by
    modifying the filter defined below.
    """
    filter_order = 2
    nyquist = (0.5 * (x[1] - x[0]))**(-1)
    cutoff = 5**(-1)
    b, a = signal.butter(filter_order, min(1, cutoff/nyquist), btype='lowpass', output='ba')
    filter_data = signal.lfilter(b, a, y)
    return filter_data

def high_filter_SPE(x, y):
    """
    Returns `y` through a high pass filter. Edit the cutoff frequency by
    modifying the filter defined below.
    """
    filter_order = 2
    nyquist = (0.5 * (x[1] - x[0]))**(-1)
    cutoff = 5**(-1)  # Cut off frequency for the filter measured in inverse nanoseconds
    b, a = signal.butter(filter_order, min(1, cutoff/nyquist), btype='highpass', output='ba')
    filter_data = signal.lfilter(b, a, y)
    return filter_data

def spe_baseline_subtraction(x, y, method=1):
    """ 
    INTEGRATION METHODS
    0: Only per event median subtraction (preformed in every method).
    1 (default): For each event, subtract off the median of all points that lie above `cutoff`.
                 Then, across all events, subtract off the median of all points between `a` and `b`.
    2: Per sample median subtraction. This method is not good because the SPE signal gets diminished.
    3: Delete all trials that have an SPE between `ma` and `mb`. Subtract off the median between `ma` and `mb` on a per event basis.
    4: Same as 3, except no trials are deleted. Trials that have an SPE between `ma` and `mb` get reduced by the total median
       between `ma` and `mb` of events that don't have an SPE in this range.
    """ 
    high_filter_y = high_filter_SPE(x, y)
    
    # Integration Method 0, per event median subtraction:
    y -= np.median(y, axis=-1)[:, np.newaxis]
    
    if args.integration_method == 1:  # Default 
        cutoff = -2*iqr(high_filter_y.flatten())
        no_SPE_mask = y > cutoff 
        y -= np.array([np.median(y[i, no_SPE_mask[i]]) for i in range(len(y))])[:, np.newaxis]
        i_mask = np.logical_and(x>=args.start_time, x<args.start_time+args.integration_time)
        y -= np.median(y[:, i_mask])
    elif args.integration_method == 2:
        # `s` for samples
        s = y.T
        s_mask = s > -10*iqr(high_filter_y.flatten())
        good_s = [s[i, s_mask[i]] for i in range(len(s))]
        print(f'average number of good samples: {np.mean([len(sub) for sub in good_s])}')
        sample_medians = np.array([np.median(sub) for sub in good_s])
        y -= sample_medians
    elif args.integration_method == 3:
        ma = -25
        mb = 200
        SPE_trials = np.min(y[:, np.logical_and(x >= ma, x < mb)], axis=-1) < -2 * iqr(high_filter_y[:, np.logical_and(x >= ma, x < mb)].flatten())
        SPE_trials_idx = [i for i in range(len(y)) if SPE_trials[i]]
        y = np.delete(y, SPE_trials_idx, axis=0)
        # Subtract off the median between `ma` and `mb` per event
        y -= np.median(y[:, np.logical_and(x >= ma, x < mb)], axis=-1)[:, np.newaxis]  # per event median subtraction
        if len(y) == 0:
            print('All trials were removed')
    elif args.integration_method == 4:
        ma = -25
        mb = 200
        m_mask = np.logical_and(x>=ma, x<mb)
        no_SPE_trials_mask = np.min(y[:, m_mask], axis=-1) > -2 * iqr(high_filter_y[:, m_mask].flatten())
        y -= np.array([np.median(y[i, m_mask]) if no_SPE_trials_mask[i] else np.median((y[no_SPE_trials_mask, :])[:, m_mask]) for i in range(len(y))])[:, np.newaxis]
    elif args.integration_method != 0:
        print('Not a valid integration method. Defaulting to integration method 0')
    return y

def plot_time_volt(x, y, channel, data_type, a, b, avg_y=None, pdf=False, filename=None):
    plt.figure()
    plt.subplot(2,1,1)
    plt.plot(x,y[:100].T)
    plt.xlabel("Time (ns)")
    plt.ylabel("Voltage (V)")
    plt.axvline(x[a])
    plt.axvline(x[b])
    plt.subplot(2,1,2)
    if avg_y is not None:
        plt.plot(x,avg_y)
    else:
        plt.plot(x, np.median(y, axis=0))
    plt.xlabel("Time (ns)")
    plt.ylabel("Voltage (V)")
    plt.axvline(x[a])
    plt.axvline(x[b])
    plt.suptitle(f"{data_type} {channel}")
    if args.print_pdfs:
        if not filename:
            print('No filename specified; can not print pdf!')
        else:
            root, ext = os.path.splitext(filename)
            plt.savefig(os.path.join(args.print_pdfs, f"{root}_{data_type}_{channel}_TimeVolt.pdf"))

def plot_hist(h, pdf=False, filename=None):
    global canvas
    # Naming canvases this way will produce a runtime warning because ROOT
    # will always make a default canvas with name `c1` the first time you
    # fit a histogram. The only way I know how to get rid of it is to
    # overwrite it like this.
    c = ROOT.TCanvas(f'c{len(canvas)+1}')
    canvas.append(c)
    h.Draw()
    c.Update()
    if pdf:
        if not filename:
            print('No filename specified; can not print pdf!')
        else:
            root, ext = os.path.splitext(filename)
            c.Print(os.path.join(args.print_pdfs, f"{root}_{h.GetName()}.pdf"))

if __name__ == '__main__':
    from argparse import ArgumentParser
    import ROOT
    from ROOT import gROOT
    import matplotlib.pyplot as plt
    import psycopg2
    import psycopg2.extensions
    from btl import fit_spe_funcs
    from btl import fit_lyso_funcs

    parser = ArgumentParser(description='Analyze SPE and LYSO charges')
    parser.add_argument('filename',help='input filename (hdf5 format)')
    parser.add_argument('-o','--output', default='delete_me.root', help='output file name')
    parser.add_argument('--plot', default=False, action='store_true', help='plot the waveforms and charge integral')
    parser.add_argument('--chunks', default=10000, type=int, help='number of waveforms to process at a time')
    parser.add_argument('-t', '--integration-time', default=150, type=float, help='SPE integration length in nanoseconds.')
    parser.add_argument('-s', '--start-time',  default=50, type=float, help='start time of the SPE integration in nanoseconds.')
    parser.add_argument('--active', default=None, help='Only take data from a single channel. If not specified, all channels are analyzed.')
    parser.add_argument('--integration-method', type=int, default=1, help='Select a method of integration. Methods described in __main__')
    parser.add_argument("--print-pdfs", default=None, type=str, help="Folder to save pdfs in.")
    parser.add_argument('-u','--upload', default=False, action='store_true', help='upload results to the database')
    parser.add_argument('-i','--institution', default=None, type=Institution, choices=list(Institution), help='name of institution')
    parser.add_argument('--channel-mask', type=lambda x: int(x,0), default=0xffffffff, help='channel mask')
    parser.add_argument('--tec-a', type=float, default=None, help='TEC resistance (side A)')
    parser.add_argument('--tec-b', type=float, default=None, help='TEC resistance (side B)')
    parser.add_argument('--thermistor-a', type=float, default=None, help='Temperature (side A)')
    parser.add_argument('--thermistor-b', type=float, default=None, help='Temperature (side B)')
    parser.add_argument('-g', '--group', type=str, default=None, help='which group to analyze')
    args = parser.parse_args()

    if not args.plot:
        # Disables the canvas from ever popping up
        gROOT.SetBatch()

    if args.upload:
        if 'BTL_DB_HOST' not in os.environ:
            print("need to set BTL_DB_HOST environment variable!",file=sys.stderr)
            sys.exit(1)

        if 'BTL_DB_PASS' not in os.environ:
            print("need to set BTL_DB_PASS environment variable!",file=sys.stderr)
            sys.exit(1)

        if args.institution is None:
            print("must specify institution with -i argument!",file=sys.stderr)
            sys.exit(1)

        print("Uploading results to the database...")
        conn = psycopg2.connect(dbname='btl_qa',
                                user='btl',
                                host=os.environ['BTL_DB_HOST'],
                                password=os.environ['BTL_DB_PASS'])
        conn.set_isolation_level(psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)

        cursor = conn.cursor()

    data = {}
    ch_data = {}  
    with h5py.File(args.filename,'r') as f:
        root_f = ROOT.TFile(args.output, "recreate")
                
        if args.upload:
            if 'lyso' not in dict(f):
                print("Missing lyso data!", file=sys.stderr)
                sys.exit(1)
            if 'spe' not in dict(f):
                print("Missing SPE data!", file=sys.stderr)
                sys.exit(1)
            #for param in f['lyso'].attrs:
            #    if f['lyso'].attrs[param] != f['spe'].attrs[param]:
            #        print(f"Conflict in {param} used to take lyso and SPE data!", file=sys.stderr)
            #        sys.exit(1)
            if 'data_source' in f['lyso'].attrs:
                if f['lyso'].attrs['data_source'] != b'CAEN':
                    print("Error: trying to upload non-CAEN data!", file=sys.stderr)
                    sys.exit(1)
            else:
                print("Data source not specified!", file=sys.stderr)
                sys.exit(1)
            
            data['barcode'] = int(f['lyso'].attrs['barcode'])
            data['voltage'] = float(f['lyso'].attrs['voltage'])
            data['git_sha1'] = f['lyso'].attrs['git_sha1'].decode("UTF-8")
            data['git_dirty'] = f['lyso'].attrs['git_dirty'].decode("UTF-8")
            data['institution'] = str(args.institution)
            data['filename'] = args.filename
            data['tec_resistance_a'] = args.tec_a
            data['tec_resistance_b'] = args.tec_b
            data['temp_a'] = args.thermistor_a
            data['temp_b'] = args.thermistor_b

            cursor.execute("INSERT INTO runs (voltage, institution, git_sha1, git_dirty, filename, tec_resistance_a, tec_resistance_b, temp_a, temp_b) VALUES (%(voltage)s, %(institution)s::inst, %(git_sha1)s, %(git_dirty)s, %(filename)s, %(tec_resistance_a)s, %(tec_resistance_b)s, %(temp_a)s, %(temp_b)s) RETURNING run", data)
            result = cursor.fetchone()
            run = result[0]
        
        for group in f:
            if args.group is not None and group != args.group:
                continue

            if group != 'lyso' and group != 'spe':
                print(f"Unknown group name: \"{group}\". Skipping...")
                continue

            for channel in f[group]:
                # All relevant channels from the scope and digitizer should
                # be in this format: 'ch<channel number>'.
                if not channel.startswith('ch'):
                    continue

                ch = int(channel[2:])

                if not args.channel_mask & (1 << ch):
                    continue
                
                # Only active channel is analyzed, unless it's `None`, in
                # which case all channels are analyzed.
                if args.active and channel != args.active:
                    continue
                
                if channel not in ch_data:
                    ch_data[channel] = {'channel': int(channel[2:])}
                
                if args.upload:
                    ch_data[channel]['run'] = run
                    ch_data[channel]['barcode'] = data['barcode']
                 
                charge = []
                
                ##################
                # Integrations
                ##################
                for i in range(0, len(f[group][channel]), args.chunks):
                    print('%i/%i' % (i+1,len(f[group][channel])))
                    x, y = convert_data(f, group, channel, i, i+args.chunks)
                    if group == 'lyso':
                        a, b = get_window(x,y, left=50, right=125)
                        y -= np.median(y[:,x < x[0] + 100],axis=-1)[:,np.newaxis]
                        if 'avg_pulse_y' in ch_data[channel]:
                            ch_data[channel]['avg_pulse_y'] = (ch_data[channel]['avg_pulse_count']*ch_data[channel]['avg_pulse_y'] + len(y)*np.mean(y, axis=0)) / (ch_data[channel]['avg_pulse_count'] + len(y))
                            ch_data[channel]['avg_pulse_count'] += len(y)
                            np.append(ch_data[channel]['lyso_rise_time'], get_rise_time(x, y))
                            np.append(ch_data[channel]['lyso_fall_time'], get_fall_time(x, y))
                        else:
                            ch_data[channel]['avg_pulse_y'] = np.mean(y, axis=0)
                            ch_data[channel]['avg_pulse_count'] = len(y)
                            ch_data[channel]['avg_pulse_x'] = x
                            ch_data[channel]['lyso_rise_time'] = get_rise_time(x, y)
                            ch_data[channel]['lyso_fall_time'] = get_fall_time(x, y)
                        
                    elif group == 'spe':
                        a, b = get_spe_window(x, args.start_time, args.integration_time)
                        y = spe_baseline_subtraction(x, y, method=args.integration_method)                        

                    charge.extend(integrate(x,y, a, b))

                ch_data[channel]['%s_charge' % group] = np.array(charge)
                        
                if args.plot or args.print_pdfs:
                    if group == 'lyso':
                        avg_y = ch_data[channel]['avg_pulse_y']
                    else:
                        # avg_y for the spe waveform is only used for
                        # plotting
                        avg_y = np.mean(y, axis=0)
                    plot_time_volt(x, y, channel, group, a, b, avg_y=avg_y, pdf=args.print_pdfs)
                
        charge = np.zeros((32,max(len(ch_data[channel]['lyso_charge']) for channel in ch_data)))
        for channel in ch_data:
            ch = int(channel[2:])
            charge[ch,:len(ch_data[channel]['lyso_charge'])] = ch_data[channel]['lyso_charge']

        neighbors = {}
        for i in range(32):
            neighbors[i] = []
            if (i + 1) % 8 > i % 8:
                neighbors[i].append(i+1)
            if (i - 1) % 8 < i % 8:
                neighbors[i].append(i-1)

        for channel in ch_data:
            ch = int(channel[2:])
            ##################
            # Creating Histogram
            ##################
            # Try to get only events in which the entire beta decay and gammas
            # happen in a single crystal. To do this, we select only events in
            # which the charge in the current channel is greater than 50% of
            # it's neighbors charge (i.e. the neighbor only has crosstalk).
            selection = (charge[ch] > charge[neighbors[ch]]*0.5).all(axis=0)
            lyso_bins = get_bins(charge[ch][selection], cutoff=100)
            hlyso = ROOT.TH1D(f"lyso_{channel}", f"LYSO Charge Integral for {channel}", len(lyso_bins), lyso_bins[0], lyso_bins[-1])
            for x in ch_data[channel]['lyso_charge']:
                hlyso.Fill(x)
            hlyso.GetXaxis().SetTitle("Charge (pC)")
            hlyso.Write()

            spe_bins = get_bins(ch_data[channel]['spe_charge'])
            hspe = ROOT.TH1D(f"spe_{channel}", f"LYSO Charge Integral for {channel}", len(spe_bins), spe_bins[0], spe_bins[-1])
            for x in ch_data[channel]['spe_charge']:
                hspe.Fill(x)
            hspe.GetXaxis().SetTitle("Charge (pC)")
            hspe.Write()

            ##################
            # Preparing Data for Upload
            ##################
            if args.upload:
                ch_data[channel]['lyso_rise_time'] = float(np.median(ch_data[channel]['lyso_rise_time']))
                ch_data[channel]['lyso_fall_time'] = float(np.median(ch_data[channel]['lyso_rise_time']))
                ch_data[channel]['avg_pulse_x'] = list(map(float,ch_data[channel]['avg_pulse_x']))
                ch_data[channel]['avg_pulse_y'] = list(map(float,ch_data[channel]['avg_pulse_y']))
                lyso_bincenters = (lyso_bins[1:] + lyso_bins[:-1])/2
                ch_data[channel]['lyso_charge_histogram_y'] = list(map(float,np.histogram(ch_data[channel]['lyso_charge'],bins=lyso_bins)[0]))
                ch_data[channel]['lyso_charge_histogram_x'] = list(map(float,lyso_bincenters))
                ch_data[channel]['spe_charge_histogram_y'] = list(map(float,np.histogram(ch_data[channel]['spe_charge'],bins=spe_bins)[0]))
                ch_data[channel]['spe_charge_histogram_x'] = list(map(float,spe_bincenters))

            ##################
            # Fitting Histogram
            ##################
            print(f'Fitting LYSO {channel}!')
            lyso_fit_pars = fit_lyso_funcs.fit_lyso(hlyso)
            if lyso_fit_pars is not None:
                ch_data[channel]['lyso_fit_pars'] = lyso_fit_pars[0]
                ch_data[channel]['lyso_fit_par_errors'] = lyso_fit_pars[1]
                ch_data[channel]['pc_per_kev'] = lyso_fit_pars[0][0]
            else:
                ch_data[channel]['lyso_fit_pars'] = None
                ch_data[channel]['lyso_fit_par_errors'] = None
                ch_data[channel]['pc_per_kev'] = None

            model = fit_spe_funcs.vinogradov_model()
            spe_fit_pars = fit_spe_funcs.fit_spe(hspe, model)
            if spe_fit_pars is not None:
                ch_data[channel]['spe_fit_pars'] = spe_fit_pars[0]
                ch_data[channel]['spe_fit_par_errors'] = spe_fit_pars[0]
                ch_data[channel]['spe'] = spe_fit_pars[0][3]
            else:
                ch_data[channel]['spe_fit_pars'] = None
                ch_data[channel]['spe_fit_par_errors'] = None
                ch_data[channel]['spe'] = None
            
            plot_hist(hlyso, pdf=args.print_pdfs, filename=args.filename)
            plot_hist(hspe, pdf=args.print_pdfs, filename=args.filename)
            
    ##################
    # Reviewing Data
    ##################
    for channel in ch_data:
        if 'pc_per_kev' not in ch_data[channel]:
            print(f'Mising lyso data for {channel}!')
        elif 'spe' not in ch_data[channel]:
            print(f'Missing SPE data for {channel}!')
        elif ch_data[channel]['pc_per_kev'] is None:
            print(f'Failed to fit {channel} lyso histogram!')
        elif ch_data[channel]['spe'] is None:
            print(f'Failed to fit {channel} spe histogram!')
        else:
            print(f'{channel}: {ch_data[channel]["pc_per_kev"]*1000*4/ch_data[channel]["spe"]}')
            
            ##################
            # Uploading Data
            ##################
            if args.upload:
                result = cursor.execute("INSERT INTO data (channel, barcode, pc_per_kev, spe, lyso_rise_time, lyso_fall_time, lyso_charge_histogram_x, lyso_charge_histogram_y, spe_charge_histogram_x, spe_charge_histogram_y, avg_pulse_x, avg_pulse_y, run, spe_fit_pars, lyso_fit_pars, spe_fit_par_errors, lyso_fit_par_errors) VALUES (%(channel)s, %(barcode)s, %(pc_per_kev)s, %(spe)s, %(lyso_rise_time)s, %(lyso_fall_time)s, %(lyso_charge_histogram_x)s, %(lyso_charge_histogram_y)s, %(spe_charge_histogram_x)s, %(spe_charge_histogram_y)s, %(avg_pulse_x)s, %(avg_pulse_y)s, %(run)s, %(spe_fit_pars)s, %(lyso_fit_pars)s, %(spe_fit_par_errors)s, %(lyso_fit_par_errors)s)", ch_data[channel])

    root_f.Close()

    if args.plot:
        plt.show()

