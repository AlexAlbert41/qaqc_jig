#!/usr/bin/env python3
"""
Creates charge histograms from hdf5 files made from `wavedump` or `acquire-waveforms`.
"""

from __future__ import print_function, division
import h5py
import numpy as np
import pandas as pd
from scipy import signal

def iqr(x):
    return np.percentile(x,75) - np.percentile(x,25)

def get_threshold_crossing(x, data, threshold=0.4, rising=True):
    """
    Returns the times at which the waveforms in `x` cross 40% of their minimum
    value.
    """
    data = np.asarray(data)
    argmin = np.argmin(data,axis=-1)
    thresholds = threshold*data[np.arange(data.shape[0]),argmin]
    if rising:
        il = data.shape[1]-np.argmax(((np.arange(data.shape[1]) < argmin[:,np.newaxis]) & (data > thresholds[:,np.newaxis]))[:,::-1],axis=-1)-1
        ir = il + 1
        ir[ir >= data.shape[1]] = data.shape[1]-1
        i = np.arange(data.shape[0])
        return x[il] + (thresholds-data[i,il])*(x[ir]-x[il])/(data[i,ir]-data[i,il])
    else:
        il = data.shape[1]-np.argmax(((np.arange(data.shape[1]) > argmin[:,np.newaxis]) & (data < thresholds[:,np.newaxis]))[:,::-1],axis=-1)-1
        ir = il + 1
        ir[ir >= data.shape[1]] = data.shape[1]-1
        i = np.arange(data.shape[0])
        return x[il] + (thresholds-data[i,il])*(x[ir]-x[il])/(data[i,ir]-data[i,il])

def get_rise_time(x, data):
    t10 = get_threshold_crossing(x, data, 0.1)
    t90 = get_threshold_crossing(x, data, 0.9)
    return t90 - t10

def get_fall_time(x, data):
    t10 = get_threshold_crossing(x, data, 0.1, rising=False)
    t90 = get_threshold_crossing(x, data, 0.9, rising=False)
    return t10 - t90

def get_times(x, data, baseline=10):
    """
    Returns the times at which the waveforms in `x` cross 40% of their minimum
    value.
    """
    data = np.asarray(data)
    # Get the first 10 ns of every waveform to calculate the noise level
    noise = iqr(data[:,np.where(x < x[0] + baseline)[0]])
    # Get events with a pulse
    pulses = np.min(data,axis=-1) < -noise*5
    # Select events with pulses. If there are no matches (which might be the
    # case for the triggering channel), then don't apply the selection.
    if np.count_nonzero(pulses):
        data = data[pulses]
    argmin = np.argmin(data,axis=-1)
    threshold = 0.4*data[np.arange(data.shape[0]),argmin]
    return x[data.shape[1]-np.argmax(((np.arange(data.shape[1]) < argmin[:,np.newaxis]) & (data > threshold[:,np.newaxis]))[:,::-1],axis=-1)-1]

def get_spe_window(x, start, integration_time):
    """
    Returns the indicies over which the SPE analysis should be integrated.

    `start` and `integration_time` are in nanoseconds, not indexes.
    `start` is relative to the trigger, so `start = 0` is not 
    the first sample, but rather the time the trigger fired.
    """
    time_per_index = x[1] - x[0]
    a = int(np.abs(x - start).argmin())
    if a >= len(x) - 1:
        print('SPE integration start time exceeds the acquisition window! Quitting...', file=sys.stderr)
        sys.exit(1)
    b = int(np.round(a + integration_time / time_per_index))
    if b > len(x) - 1:
        print('SPE integration time is too long! Quitting...', file=sys.stderr)
        sys.exit(1)
    return (a,b)

def get_window(x, data, left=1, right=10):
    """
    Returns the indices start and stop over which you should integrate the
    waveforms in `x`. The window is found by calculating the median hit time
    for all pulses in `x` and then going back 10 ns and forward 125 ns for sodium and 10 ns otherwise.
    """
    # FIXME
    # This method should incorportate get_threshold_crossing
    data = np.asarray(data)
    t = (x,data)
    mean_hit_time = np.median(t)
    a, b = np.searchsorted(x,[mean_hit_time-left,mean_hit_time+right])
    if a < 0:
        a = 0
    if b > len(x) - 1:
        b = len(x) - 1
    return a, b

def integrate(x, data, a, b):
    """
    Integrate all waveforms in `data` with times `x`.
    """
    # i = v/r
    # divide by 50 ohms to convert to a charge
    if np.ndim(data) == 2:
        return -np.trapz(data[:,a:b],x=x[a:b])*1000/50.0
    else:
        return -np.trapz(data[a:b],x=x[a:b])*1000/50.0

def get_bins(x):
    """
    Returns bins for the data `x` using the Freedman Diaconis rule. See
    https://en.wikipedia.org/wiki/Freedman%E2%80%93Diaconis_rule.
    
    The equation below returns bins using said rule. A smaller bin value than this was chosen after finetuning for better fitting results.
    bin_width = 2*iqr(x)/(len(x)**(1/3.0))
    """
    
    bin_width = 0.5*iqr(x)/(len(x)**(1/3.0))
    if bin_width == 0:
        print('Zero bin width! Quitting...', file=stderr)
        sys.exit(1)
    return np.arange(np.min(x),np.max(x),bin_width)

def chunks(lst, n):
    """Yield successive n-sized chunks from lst."""
    for i in range(0, len(lst), n):
        yield (i,i + n)

def convert_data(f, channel, start, stop):
    """
    Reads data from opened hdf5 file `f`.
    Gets the events from `start` to `stop` in the dataset `channel`.
    """    
    if 'data_source' in list(f.attrs):
        if f.attrs['data_source'] == b'CAEN':
            
            xinc = 1/(f.attrs['drs4_frequency'] * 10**6)
            points = f.attrs['record_length']
            x = np.linspace(0, xinc * points, int(points)) - xinc * points * (1 - f.attrs['post_trigger']/100)

            y = f[channel][start:stop] * (1/2**12)

    elif 'yinc' in dict(f[channel].attrs):
        x = f[channel].attrs['xorg'] + np.linspace(0,f[channel].attrs['xinc']*f[channel].attrs['points'],int(f[channel].attrs['points']))
        # FIXME
        # I believe the else block in this if/else statement was for a type of hdf5 format that we no longer use.
        if True: # ':WAVeform:FORMat' in dict(f['settings'].attrs) and f['settings'].attrs[':WAVeform:FORMat'] != 'ASC':
            # convert word values -> voltages if the data was saved in a non-ascii format
            y = f[channel][start:stop]*f[channel].attrs['yinc'] + f[channel].attrs['yorg']
        else:
            y = f[channel][start:stop]
    else:
        # In older versions of the code, I stored xorg, xinc, etc.
        # in the main HDF5 group and not on a per channel basis
        x = f.attrs['xorg'] + np.linspace(0,f.attrs['xinc']*f.attrs['points'],int(f.attrs['points']))

        if ':WAVeform:FORMat' in dict(f['settings'].attrs) and f['settings'].attrs[':WAVeform:FORMat'] != 'ASC':
            # convert word values -> voltages if the data was saved in a non-ascii format
            y = f[channel][start:stop]*f.attrs['yinc'] + f.attrs['yorg']
        else:
            y = f[channel][start:stop]
    return x*1e9, y

def low_filter_SPE(x, y):
    """
    Returns `y` through a low pass filter. Edit the cutoff frequency by modifying the filter defined below.
    """
    filter_order = 2
    nyquist = (0.5 * (x[1] - x[0]))**(-1)
    cutoff = 5**(-1)
    b, a = signal.butter(filter_order, min(1, cutoff/nyquist), btype='lowpass', output='ba')
    filter_data = signal.lfilter(b, a, y)
    return filter_data

def high_filter_SPE(x, y):
    """
    Returns `y` through a high pass filter. Edit the cutoff frequency by modifying the filter defined below.
    """
    filter_order = 2
    nyquist = (0.5 * (x[1] - x[0]))**(-1)
    cutoff = 5**(-1)  # Cut off frequency for the filter measured in inverse nanoseconds
    b, a = signal.butter(filter_order, min(1, cutoff/nyquist), btype='highpass', output='ba')
    filter_data = signal.lfilter(b, a, y)
    return filter_data

if __name__ == '__main__':
    from argparse import ArgumentParser
    import ROOT
    import matplotlib.pyplot as plt

    parser = ArgumentParser(description='Analyze SPE and 511 charges')
    parser.add_argument('filenames',nargs='+',help='input filenames (hdf5 format)')
    parser.add_argument('-o','--output', default=None, help='output file name', required=True)
    parser.add_argument('--sodium', default=False, action='store_true', help='flag to indicate data is from a sodium source')
    parser.add_argument('--plot', default=False, action='store_true', help='plot the waveforms and charge integral')
    parser.add_argument('--chunks', default=10000, type=int, help='number of waveforms to process at a time')
    parser.add_argument('-it', '--integration_time', default=300, type=float, help='SPE integration length in nanoseconds.')
    parser.add_argument('-s', '--start_time',  default=50, type=float, help='start time of the SPE integration in nanoseconds.')
    parser.add_argument('--active', default=None, help='Only take data from a single channel. If not specified, all channels are analyzed.')
    parser.add_argument('-im', '--integration_method', type=int, default=1, help='Select a method of integration. Methods described in __main__')
    parser.add_argument("--print_pdfs", default=None, type=str, help="Folder to save pdfs in.")

    args = parser.parse_args()

    charge = {}
    f_charge = {}
    # Only active channel is analyzed, unless it's the empty string, in which case all channels are analyzed.
    active_ch = args.active
    for filename in args.filenames:
        with h5py.File(filename) as f:
            for channel in f:
                # All relevant channels, from scope and digitizer, should be in this format: 'ch<channel number>'.
                if channel == 'settings':
                    continue
                if channel.startswith('b'):  # baseline channel, only relevant for testing
                    continue
                if active_ch:
                    if channel != active_ch:
                        continue

                N = len(f[channel])
                
                for i in range(0, N, args.chunks):
                    x, y = convert_data(f,channel,i,i+args.chunks)
                    if args.sodium:
                        a, b = get_window(x,y,left=50,right=300)
                        y -= np.median(y[:,x < x[0] + 100],axis=-1)[:,np.newaxis]
                        if channel in charge:
                            charge[channel] = np.concatenate((charge[channel],integrate(x,y, a, b)))
                        else:
                            charge[channel] = integrate(x,y, a, b)
                    else:
                        a, b = get_spe_window(x, args.start_time, args.integration_time)
                        
                        high_filter_y = high_filter_SPE(x, y)
                        y -= np.median(y, axis=-1)[:, np.newaxis]  # per event median subtraction
                        
                        ################################
                        # INTEGRATION METHODS
                        # 0: Only per event median subtraction
                        # 1 (default): For each event, subtract off the median of all points that lie above `cutoff`.
                        #              Then, across all events, subtract off the median of all points between `a` and `b`.
                        # 2: Per sample median subtraction. This method is not good because the SPE signal gets diminished.
                        # 3: Delete all trials that have an SPE between `ma` and `mb`. Subtract off the median between `ma` and `mb` on a per event basis.
                        # 4: Same as 3, except no trials are deleted. Trials that have an SPE between `ma` and `mb` get reduced by the total median
                        #    between `ma` and `mb` of events that don't have an SPE in this range.
                        ################################
                        if args.integration_method == 1:
                            cutoff = -2*iqr(high_filter_y.flatten())
                            no_SPE_mask = y > cutoff 
                            y -= np.array([np.median(y[i, no_SPE_mask[i]]) for i in range(len(y))])[:, np.newaxis]
                            i_mask = np.logical_and(x>=args.start_time, x<args.start_time+args.integration_time)
                            y -= np.median(y[:, i_mask])
                        elif args.integration_method == 2:
                            # `s` for samples
                            s = y.T
                            s_mask = s > -10*iqr(high_filter_y.flatten())
                            good_s = [s[i, s_mask[i]] for i in range(len(s))]
                            print(f'average number of good samples: {np.mean([len(sub) for sub in good_s])}')
                            sample_medians = np.array([np.median(sub) for sub in good_s])
                            y -= sample_medians
                        elif args.integration_method == 3:
                            ma = -25
                            mb = 200
                            SPE_trials = np.min(y[:, np.logical_and(x >= ma, x < mb)], axis=-1) < -2 * iqr(high_filter_y[:, np.logical_and(x >= ma, x < mb)].flatten())
                            SPE_trials_idx = [i for i in range(len(y)) if SPE_trials[i]]
                            y = np.delete(y, SPE_trials_idx, axis=0)
                            # Subtract off the median between `ma` and `mb` per event
                            y -= np.median(y[:, np.logical_and(x >= ma, x < mb)], axis=-1)[:, np.newaxis]  # per event median subtraction
                            if len(y) == 0:
                                print('All trials were removed')
                        elif args.integration_method == 4:
                            ma = -25
                            mb = 200
                            m_mask = np.logical_and(x>=ma, x<mb)
                            no_SPE_trials_mask = np.min(y[:, m_mask], axis=-1) > -2 * iqr(high_filter_y[:, m_mask].flatten())
                            y -= np.array([np.median(y[i, m_mask]) if no_SPE_trials_mask[i] else np.median((y[no_SPE_trials_mask, :])[:, m_mask]) for i in range(len(y))])[:, np.newaxis]
                        else:
                            print('Not a valid integration method. Defaulting to integration method 0')

                        if channel in charge:
                            charge[channel] = np.concatenate((charge[channel],integrate(x,y, a, b)))
                            f_charge[channel] = np.concatenate((f_charge[channel], integrate(x, high_filter_y, a, b))) 
                        else:
                            charge[channel] = integrate(x,y, a, b)
                            f_charge[channel] = integrate(x, high_filter_y, a, b)
                    
                if args.plot or args.pdf:
                    plt.figure()
                    plt.subplot(2,1,1)
                    plt.plot(x,y[:100].T)
                    plt.xlabel("Time (ns)")
                    plt.ylabel("Voltage (V)")
                    plt.axvline(x[a])
                    plt.axvline(x[b])
                    plt.subplot(2,1,2)
                    plt.plot(x,np.median(y,axis=0))
                    plt.xlabel("Time (ns)")
                    plt.ylabel("Voltage (V)")
                    plt.axvline(x[a])
                    plt.axvline(x[b])
                    plt.suptitle(channel)
                if args.print_pdfs:
                    root, ext = os.path.splitext(filename)
                    plt.savefig(os.path.join(args.print_pdfs, f"{root}_{channel}_TimeVolt_{args.start_time}_{args.integration_time}.pdf"))
                
                # Plotting the filtered voltage signal. Doesn't have to be included in the final draft of this code.
                if (active_ch == channel) and (args.plot or args.pdf):
                    plt.figure()
                    plt.subplot(2,1,1)
                    plt.plot(x,high_filter_y[:100].T)
                    plt.xlabel("Time (ns)")
                    plt.ylabel("Voltage (V)")
                    plt.axvline(x[a])
                    plt.axvline(x[b])
                    plt.subplot(2,1,2)
                    plt.plot(x,np.median(high_filter_y,axis=0))
                    plt.xlabel("Time (ns)")
                    plt.ylabel("Voltage (V)")
                    plt.axvline(x[a])
                    plt.axvline(x[b])
                    plt.suptitle(channel)
                
    f = ROOT.TFile(args.output,"recreate")
    for channel in charge:
        bins = get_bins(charge[channel])
        h = ROOT.TH1D(channel,"Charge Integral for %s" % channel,len(bins),bins[0],bins[-1])
        for x in charge[channel]:
            h.Fill(x)
        h.GetXaxis().SetTitle("Charge (pC)")
        
        if args.plot or args.pdf:
            plt.figure()
            plt.hist(charge[channel],bins=bins,histtype='step',label=channel)
            plt.xlabel("Charge (pC)")
            plt.legend()
        if args.print_pdfs:
            root, ext = os.path.splitext(filename)
            plt.savefig(os.path.join(args.print_pdfs, f"{root}_{channel}_{args.start_time}_{args.integration_time}.pdf"))
        h.Write()

    # The prefix `f_` will be used to denote objects that correspond to filtered data.
        f_bins = get_bins(f_charge[channel])
        f_h = ROOT.TH1D(f'f_{channel}', "Filtered Charge Integral for %s" % channel, len(f_bins), f_bins[0], f_bins[-1])
        for x in f_charge[channel]:
            f_h.Fill(x)
        f_h.GetXaxis().SetTitle('Charge (pC)')
        f_h.Write()
    f.Close()

    if args.plot:
        plt.show()
